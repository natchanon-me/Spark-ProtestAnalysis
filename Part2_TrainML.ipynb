{"cells": [{"cell_type": "code", "execution_count": 1, "id": "afe82698", "metadata": {}, "outputs": [], "source": "import numpy as np\n\nimport findspark\nfindspark.init()"}, {"cell_type": "code", "execution_count": 2, "id": "f0435fee", "metadata": {}, "outputs": [], "source": "#1 - import module\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\nimport numpy\nimport pandas"}, {"cell_type": "code", "execution_count": 3, "id": "859008fd", "metadata": {}, "outputs": [], "source": "# GCS Config\nGCP_PROJECT = 'NS01-Project'\nMODEL_BUCKET = 'gs://twitter_testtt'\nVERSION_NAME = 'v1'\nMODEL_NAME = 'xgmodel'"}, {"cell_type": "code", "execution_count": 4, "id": "239b88f2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<pyspark.sql.session.SparkSession object at 0x7f5337f73a00>\n"}], "source": "#3 - Setup SparkSession (SparkSQL)\nspark = (SparkSession\n         .builder\n         .appName(\"DataFrameHandOn\")\n         .master(\"local[*]\")\n         .getOrCreate())\nprint(spark)"}, {"cell_type": "code", "execution_count": 5, "id": "0a1aa445", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 1:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "finish caching data\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "df = spark.read.csv(\"gs://twitter_testtt/labeled_data.csv\", header=True, inferSchema=True)\ndf.cache()\nprint(\"finish caching data\")"}, {"cell_type": "code", "execution_count": 6, "id": "5d131eea", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "\r[Stage 2:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---+-----+-----------+------------------+-------+-----+--------------------+\n|_c0|count|hate_speech|offensive_language|neither|class|               tweet|\n+---+-----+-----------+------------------+-------+-----+--------------------+\n|  0|    3|          0|                 0|      3|    2|!!! RT @mayasolov...|\n|  1|    3|          0|                 3|      0|    1|!!!!! RT @mleew17...|\n|  2|    3|          0|                 3|      0|    1|!!!!!!! RT @UrKin...|\n|  3|    3|          0|                 2|      1|    1|!!!!!!!!! RT @C_G...|\n|  4|    6|          0|                 6|      0|    1|!!!!!!!!!!!!! RT ...|\n+---+-----+-----------+------------------+-------+-----+--------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "df.show(5)"}, {"cell_type": "code", "execution_count": 7, "id": "a6927df2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- _c0: string (nullable = true)\n |-- count: string (nullable = true)\n |-- hate_speech: string (nullable = true)\n |-- offensive_language: string (nullable = true)\n |-- neither: integer (nullable = true)\n |-- class: integer (nullable = true)\n |-- tweet: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 8, "id": "98e365a4", "metadata": {}, "outputs": [], "source": "pd_df = df.toPandas()"}, {"cell_type": "code", "execution_count": 9, "id": "5187fc2e", "metadata": {"scrolled": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_c0</th>\n      <th>count</th>\n      <th>hate_speech</th>\n      <th>offensive_language</th>\n      <th>neither</th>\n      <th>class</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"!!!!!!!!!!!!!!!!!!\"\"@T_Madison_x: The shit ju...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"!!!!!!\"\"@__BrighterDays: I can not just sit u...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" &amp;amp; you might not get ya bitch back &amp;amp...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" @rhythmixx_ :hobbies include: fighting Mar...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>bitch\"</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" Keeks is a bitch she curves everyone \"\" lo...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" Murda Gang bitch its Gang Land \"\"\"</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>12</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>\"\"\" So hoes that smoke are losers ? \"\" yea ......</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" bad bitches is the only thing that i like \"\"\"</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" bitch get up off me \"\"\"</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>15</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" bitch nigga miss me with it \"\"\"</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" bitch plz whatever \"\"\"</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" bitch who do you love \"\"\"</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>18</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" bitches get cut off everyday B \"\"\"</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>19</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" black bottle &amp;amp; a bad bitch \"\"\"</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>20</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" broke bitch cant tell me nothing \"\"\"</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>21</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" cancel that bitch like Nino \"\"\"</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>22</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" cant you see these hoes wont change \"\"\"</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>23</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" fuck no that bitch dont even suck dick \"\" ...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>24</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" got ya bitch tip toeing on my hardwood flo...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>25</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>\"\"\" her pussy lips like Heaven doors \"\" &amp;#1285...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>26</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" hoe what its hitting for \"\"\"</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>27</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" i met that pussy on Ocean Dr . i gave that...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>28</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>\"\"\" i need a trippy bitch who fuck on Hennessy...</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "       _c0 count hate_speech offensive_language  neither  class  \\\n0        0     3           0                  0      3.0    2.0   \n1        1     3           0                  3      0.0    1.0   \n2        2     3           0                  3      0.0    1.0   \n3        3     3           0                  2      1.0    1.0   \n4        4     6           0                  6      0.0    1.0   \n5        5     3           1                  2      0.0    1.0   \n6        6     3           0                  3      0.0    1.0   \n7        7     3           0                  3      0.0    1.0   \n8        8     3           0                  3      0.0    1.0   \n9        9     3           1                  2      0.0    1.0   \n10  bitch\"  None        None               None      NaN    NaN   \n11      10     3           0                  3      0.0    1.0   \n12      11     3           0                  3      0.0    1.0   \n13      12     3           0                  2      1.0    1.0   \n14      13     3           0                  3      0.0    1.0   \n15      14     3           1                  2      0.0    1.0   \n16      15     3           0                  3      0.0    1.0   \n17      16     3           0                  3      0.0    1.0   \n18      17     3           1                  2      0.0    1.0   \n19      18     3           0                  3      0.0    1.0   \n20      19     3           0                  3      0.0    1.0   \n21      20     3           0                  3      0.0    1.0   \n22      21     3           0                  3      0.0    1.0   \n23      22     3           0                  3      0.0    1.0   \n24      23     3           0                  3      0.0    1.0   \n25      24     3           0                  3      0.0    1.0   \n26      25     3           0                  2      1.0    1.0   \n27      26     3           0                  3      0.0    1.0   \n28      27     3           0                  3      0.0    1.0   \n29      28     3           0                  3      0.0    1.0   \n\n                                                tweet  \n0   !!! RT @mayasolovely: As a woman you shouldn't...  \n1   !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n2   !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n3   !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n4   !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n5   \"!!!!!!!!!!!!!!!!!!\"\"@T_Madison_x: The shit ju...  \n6   \"!!!!!!\"\"@__BrighterDays: I can not just sit u...  \n7   !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n8   \"\"\" &amp; you might not get ya bitch back &amp...  \n9   \"\"\" @rhythmixx_ :hobbies include: fighting Mar...  \n10                                               None  \n11  \"\"\" Keeks is a bitch she curves everyone \"\" lo...  \n12             \"\"\" Murda Gang bitch its Gang Land \"\"\"  \n13  \"\"\" So hoes that smoke are losers ? \"\" yea ......  \n14  \"\"\" bad bitches is the only thing that i like \"\"\"  \n15                        \"\"\" bitch get up off me \"\"\"  \n16                \"\"\" bitch nigga miss me with it \"\"\"  \n17                         \"\"\" bitch plz whatever \"\"\"  \n18                      \"\"\" bitch who do you love \"\"\"  \n19             \"\"\" bitches get cut off everyday B \"\"\"  \n20             \"\"\" black bottle &amp; a bad bitch \"\"\"  \n21           \"\"\" broke bitch cant tell me nothing \"\"\"  \n22                \"\"\" cancel that bitch like Nino \"\"\"  \n23        \"\"\" cant you see these hoes wont change \"\"\"  \n24  \"\"\" fuck no that bitch dont even suck dick \"\" ...  \n25  \"\"\" got ya bitch tip toeing on my hardwood flo...  \n26  \"\"\" her pussy lips like Heaven doors \"\" &#1285...  \n27                   \"\"\" hoe what its hitting for \"\"\"  \n28  \"\"\" i met that pussy on Ocean Dr . i gave that...  \n29  \"\"\" i need a trippy bitch who fuck on Hennessy...  "}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "pd_df.head(30)"}, {"cell_type": "code", "execution_count": 10, "id": "a3ad2605", "metadata": {}, "outputs": [], "source": "df = df.dropna()"}, {"cell_type": "code", "execution_count": 11, "id": "2d724328", "metadata": {}, "outputs": [], "source": "from pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import udf\n\ndef onlyTwoClass(x):\n    return 1 if str(x)>str(1) else 0\n\nmy_udf = udf(onlyTwoClass, IntegerType())"}, {"cell_type": "code", "execution_count": 12, "id": "e3fad20f", "metadata": {}, "outputs": [], "source": "new_df = df.withColumn('class', my_udf('class'))"}, {"cell_type": "code", "execution_count": 13, "id": "d272d983", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- _c0: string (nullable = true)\n |-- count: string (nullable = true)\n |-- hate_speech: string (nullable = true)\n |-- offensive_language: string (nullable = true)\n |-- neither: integer (nullable = true)\n |-- class: integer (nullable = true)\n |-- tweet: string (nullable = true)\n\n"}], "source": "new_df.printSchema()"}, {"cell_type": "code", "execution_count": 14, "id": "e3c6f766", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "\r[Stage 4:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---+-----+-----------+------------------+-------+-----+--------------------+\n|_c0|count|hate_speech|offensive_language|neither|class|               tweet|\n+---+-----+-----------+------------------+-------+-----+--------------------+\n|  0|    3|          0|                 0|      3|    1|!!! RT @mayasolov...|\n|  1|    3|          0|                 3|      0|    0|!!!!! RT @mleew17...|\n|  2|    3|          0|                 3|      0|    0|!!!!!!! RT @UrKin...|\n|  3|    3|          0|                 2|      1|    0|!!!!!!!!! RT @C_G...|\n|  4|    6|          0|                 6|      0|    0|!!!!!!!!!!!!! RT ...|\n|  5|    3|          1|                 2|      0|    0|\"!!!!!!!!!!!!!!!!...|\n|  6|    3|          0|                 3|      0|    0|\"!!!!!!\"\"@__Brigh...|\n|  7|    3|          0|                 3|      0|    0|!!!!&#8220;@selfi...|\n|  8|    3|          0|                 3|      0|    0|\"\"\" &amp; you mig...|\n|  9|    3|          1|                 2|      0|    0|\"\"\" @rhythmixx_ :...|\n+---+-----+-----------+------------------+-------+-----+--------------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "new_df.show(10)"}, {"cell_type": "code", "execution_count": 15, "id": "afa4ae57", "metadata": {}, "outputs": [], "source": "# Drop unused column\nnew_df = new_df.drop(\"count\", \"hate_speech\", \"offensive_language\", \"neither\")"}, {"cell_type": "code", "execution_count": 16, "id": "0e3e3e5a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+--------------------+\n|_c0|class|               tweet|\n+---+-----+--------------------+\n|  0|    1|!!! RT @mayasolov...|\n|  1|    0|!!!!! RT @mleew17...|\n|  2|    0|!!!!!!! RT @UrKin...|\n|  3|    0|!!!!!!!!! RT @C_G...|\n|  4|    0|!!!!!!!!!!!!! RT ...|\n|  5|    0|\"!!!!!!!!!!!!!!!!...|\n|  6|    0|\"!!!!!!\"\"@__Brigh...|\n|  7|    0|!!!!&#8220;@selfi...|\n|  8|    0|\"\"\" &amp; you mig...|\n|  9|    0|\"\"\" @rhythmixx_ :...|\n+---+-----+--------------------+\nonly showing top 10 rows\n\n"}], "source": "new_df.show(10)"}, {"cell_type": "code", "execution_count": 17, "id": "c05d9aae", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "\r[Stage 6:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+-----+\n|class|count|\n+-----+-----+\n|    1| 4163|\n|    0|20620|\n+-----+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "new_df.groupBy(\"class\").count().show()"}, {"cell_type": "code", "execution_count": 18, "id": "bfec6007", "metadata": {}, "outputs": [], "source": "# DATA Cleaning"}, {"cell_type": "code", "execution_count": 19, "id": "6d87614a", "metadata": {}, "outputs": [], "source": "import re\n\ndef preprocess(text_string):\n    \"\"\"\n    Accepts a text string and replaces:\n    1) urls with URLHERE\n    2) lots of whitespace with one instance\n    3) mentions with MENTIONHERE\n\n    This allows us to get standardized counts of urls and mentions\n    Without caring about specific people mentioned\n    \"\"\"\n    space_pattern = '\\s+'\n    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    mention_regex = '@[\\w\\-]+'\n    parsed_text = re.sub(space_pattern, ' ', str(text_string))\n    parsed_text = re.sub(giant_url_regex, '', str(parsed_text))\n    parsed_text = re.sub(mention_regex, '', str(parsed_text))\n    parsed_text = re.sub(\"[^a-zA-Z:,]+\", ' ', str(parsed_text))\n    parsed_text = parsed_text.replace('RT', '')\n    parsed_text = parsed_text.replace('!', '')\n    parsed_text = parsed_text.replace(':', '')\n    parsed_text = parsed_text.strip('\\'\"')\n    parsed_text = parsed_text.lower()\n    parsed_text = parsed_text.lstrip()\n    \n    return parsed_text"}, {"cell_type": "code", "execution_count": 20, "id": "e989daeb", "metadata": {}, "outputs": [], "source": "txt_process_udf = udf(preprocess, StringType())\nnew_df = new_df.withColumn('tweet', txt_process_udf('tweet'))"}, {"cell_type": "code", "execution_count": 21, "id": "cedfe598", "metadata": {}, "outputs": [], "source": "new_df = new_df.dropna()"}, {"cell_type": "code", "execution_count": 22, "id": "a55da058", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+--------------------+\n|_c0|class|               tweet|\n+---+-----+--------------------+\n|  0|    1|as a woman you sh...|\n|  1|    0|boy dats cold tyg...|\n|  2|    0|dawg   you ever f...|\n|  3|    0|she look like a t...|\n|  4|    0|the shit you hear...|\n|  5|    0|the shit just blo...|\n|  6|    0|i can not just si...|\n|  7|    0|cause i m tired o...|\n|  8|    0|amp you might not...|\n|  9|    0|hobbies include f...|\n| 10|    0|keeks is a bitch ...|\n| 11|    0|murda gang bitch ...|\n| 12|    0|so hoes that smok...|\n| 13|    0|bad bitches is th...|\n| 14|    0|bitch get up off me |\n| 15|    0|bitch nigga miss ...|\n| 16|    0| bitch plz whatever |\n| 17|    0|bitch who do you ...|\n| 18|    0|bitches get cut o...|\n| 19|    0|black bottle amp ...|\n+---+-----+--------------------+\nonly showing top 20 rows\n\n"}], "source": "new_df.show(20)"}, {"cell_type": "code", "execution_count": 23, "id": "7dac8368", "metadata": {}, "outputs": [], "source": "train_df , test_df = new_df.randomSplit([0.8, 0.2])"}, {"cell_type": "markdown", "id": "1d20ee14", "metadata": {}, "source": "## Text Featurization"}, {"cell_type": "code", "execution_count": 24, "id": "303d3a48", "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import Tokenizer, Word2Vec\nfrom pyspark.ml import Pipeline"}, {"cell_type": "code", "execution_count": 25, "id": "c3721226", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "21/12/05 21:18:50 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n21/12/05 21:18:51 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"}], "source": "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\nw2v = Word2Vec(vectorSize=300, minCount=0, inputCol=\"words\", outputCol=\"Features\")\n\n#Create Pipeline\nw2v_pipeline = Pipeline(stages=[tokenizer, w2v])\n\nw2v_pipeline_model = w2v_pipeline.fit(train_df)\ntrain_df = w2v_pipeline_model.transform(train_df)\ntest_df = w2v_pipeline_model.transform(test_df)"}, {"cell_type": "code", "execution_count": 26, "id": "aac9a74f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "\r[Stage 17:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+-----+--------------------+--------------------+--------------------+\n|  _c0|class|               tweet|               words|            Features|\n+-----+-----+--------------------+--------------------+--------------------+\n|    0|    1|as a woman you sh...|[as, a, woman, yo...|[2.21605230446742...|\n|    1|    0|boy dats cold tyg...|[boy, dats, cold,...|[-0.0159893891707...|\n|  100|    0|how bout them cow...|[how, bout, them,...|[-0.0075616843532...|\n| 1000|    1|mike calls me t b...|[mike, calls, me,...|[-0.0012457987293...|\n|10000|    0|he needs too we w...|[he, needs, too, ...|[-0.0080277135923...|\n|10002|    0|he only favorites...|[he, only, favori...|[-0.0225900625093...|\n|10003|    0|he prolly gone la...|[he, prolly, gone...|[-0.0201731702416...|\n|10004|    0|he pussy whipped ...|[he, pussy, whipp...|[-0.0163165788762...|\n|10005|    0|he run his mouth ...|[he, run, his, mo...|[-0.0348054950092...|\n|10006|    0|  he said bitch boy |[he, said, bitch,...|[-0.0331203057139...|\n+-----+-----+--------------------+--------------------+--------------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "train_df.show(10)"}, {"cell_type": "code", "execution_count": 28, "id": "40a16ca6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "w2v.save(\"gs://twitter_testtt/w2v_model1\")"}, {"cell_type": "code", "execution_count": 29, "id": "c5ff36a6", "metadata": {}, "outputs": [], "source": "#w2v_test = Word2Vec.load(\"gs://twitter_testtt/w2v_model\")"}, {"cell_type": "markdown", "id": "c3441c01", "metadata": {}, "source": "### Training function"}, {"cell_type": "code", "execution_count": 30, "id": "dd0461e8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>830</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>4095</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   class  count\n0      1    830\n1      0   4095"}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": "test_df.groupby('class').count().toPandas()"}, {"cell_type": "code", "execution_count": 31, "id": "9fdf7964", "metadata": {}, "outputs": [], "source": "import xgboost as xgb\nimport numpy as np\nfrom sklearn.metrics import accuracy_score"}, {"cell_type": "code", "execution_count": 37, "id": "fa00f608", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/root/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"}, {"name": "stdout", "output_type": "stream", "text": "[21:24:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nThe accuracy score for XGboost model :  0.8976649746192893\n"}], "source": "train_features = train_df.select(\"Features\").collect()\ntrain_lables = train_df.select(\"class\").collect()\ntest_features = test_df.select(\"Features\").collect()\ntest_labels = test_df.select(\"class\").collect()\n\n\nX_train = np.asarray([v[0].toArray() for v in train_features])\nY_train = np.asarray([v[0] for v in train_lables])\nX_test =  np.asarray([v[0].toArray() for v in test_features])\nY_test = np.asarray([v[0] for v in test_labels])\n\nxgbClassifier = xgb.XGBClassifier(max_depth=20, seed=18238, objective='multi:softmax',num_class = 2)\nmodel = xgbClassifier.fit(X_train, Y_train)\npred = model.predict(X_test)\n\nauc_score = accuracy_score(Y_test,pred)\nprint (\"The accuracy score for XGboost model : \",auc_score)"}, {"cell_type": "markdown", "id": "147effc2", "metadata": {}, "source": "# SAVE MODEL PARAMS"}, {"cell_type": "code", "execution_count": 38, "id": "79ccd415", "metadata": {}, "outputs": [], "source": "model.save_model(\"model1.bst\")"}, {"cell_type": "code", "execution_count": 39, "id": "c78b3ea1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Copying file://./model.bst [Content-Type=application/octet-stream]...\n- [1 files][  1.5 MiB/  1.5 MiB]                                                \nOperation completed over 1 objects/1.5 MiB.                                      \n"}], "source": "!gsutil cp ./model.bst $MODEL_BUCKET"}, {"cell_type": "code", "execution_count": null, "id": "2236064e", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "2e0a6bcf", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "21871058", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "caf96e43", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "fd3d9e77", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "aa91c845", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "e74752a6", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "4293b98c", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "ed6f4b1b", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "538d21d8", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "c37caa90", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}