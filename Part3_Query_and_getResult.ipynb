{"cells": [{"cell_type": "code", "execution_count": 1, "id": "fdb19f0f", "metadata": {}, "outputs": [], "source": "# GCS Config\nGCP_PROJECT = 'NS01-Project'\nMODEL_BUCKET = 'gs://twitter_testtt'\nVERSION_NAME = 'v1'\nMODEL_NAME = 'xgmodel'"}, {"cell_type": "code", "execution_count": 2, "id": "6f2c5cfb", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The google.cloud.bigquery extension is already loaded. To reload it, use:\n  %reload_ext google.cloud.bigquery\n"}], "source": "%load_ext google.cloud.bigquery"}, {"cell_type": "code", "execution_count": 5, "id": "534df67c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Query complete after 0.00s: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00<00:00, 852.33query/s]                         \nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 300/300 [00:01<00:00, 299.32rows/s]\n"}], "source": "%%bigquery protest_df\nSELECT *\nFROM `ns01-project.twitter_data.tweets`\nLIMIT 2000"}, {"cell_type": "code", "execution_count": 6, "id": "c7c9511f", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>lang</th>\n      <th>location</th>\n      <th>posted_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1468665145928867844</td>\n      <td>RT @NadiaWhittomeMP: The Downing Street party ...</td>\n      <td>en</td>\n      <td>the simulation</td>\n      <td>2021-12-08 19:33:51</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1468665159304368128</td>\n      <td>RT @MintPressNews: \"Media bears a responsibili...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>2021-12-08 19:33:55</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1468665170071281671</td>\n      <td>Woooiiiii folks in this space are saying they'...</td>\n      <td>en</td>\n      <td>London, England</td>\n      <td>2021-12-08 19:33:57</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1468665186772869124</td>\n      <td>RT @live_Tripathi: \u0913\u092e\u0940\u0915\u094d\u0930\u094b\u0928 \u0915\u093e \u0916\u094c\u092b: AKTU \u0915\u0947 \u091b\u093e...</td>\n      <td>hi</td>\n      <td>None</td>\n      <td>2021-12-08 19:34:01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1468665193391697940</td>\n      <td>Where and when do we get out on the streets to...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>2021-12-08 19:34:03</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>1468666224292806662</td>\n      <td>@IAmCiele @thenixmin @doshinswitch @Evoltal_ @...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>2021-12-08 19:38:09</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>1468666228088532994</td>\n      <td>RT @timeindawater1: 5.5.Donald Trump was not p...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>2021-12-08 19:38:09</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>1468666229468667904</td>\n      <td>RT @newsbht1: London chaos: Capital gripped by...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>2021-12-08 19:38:10</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>1468666233591681030</td>\n      <td>RT @NadiaWhittomeMP: The Downing Street party ...</td>\n      <td>en</td>\n      <td>None</td>\n      <td>2021-12-08 19:38:11</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>1468666238477864962</td>\n      <td>RT @AzamBaloshi: PPP District South Held Prote...</td>\n      <td>en</td>\n      <td>Karachi, Pakistan</td>\n      <td>2021-12-08 19:38:12</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows \u00d7 5 columns</p>\n</div>", "text/plain": "                      id                                               text  \\\n0    1468665145928867844  RT @NadiaWhittomeMP: The Downing Street party ...   \n1    1468665159304368128  RT @MintPressNews: \"Media bears a responsibili...   \n2    1468665170071281671  Woooiiiii folks in this space are saying they'...   \n3    1468665186772869124  RT @live_Tripathi: \u0913\u092e\u0940\u0915\u094d\u0930\u094b\u0928 \u0915\u093e \u0916\u094c\u092b: AKTU \u0915\u0947 \u091b\u093e...   \n4    1468665193391697940  Where and when do we get out on the streets to...   \n..                   ...                                                ...   \n295  1468666224292806662  @IAmCiele @thenixmin @doshinswitch @Evoltal_ @...   \n296  1468666228088532994  RT @timeindawater1: 5.5.Donald Trump was not p...   \n297  1468666229468667904  RT @newsbht1: London chaos: Capital gripped by...   \n298  1468666233591681030  RT @NadiaWhittomeMP: The Downing Street party ...   \n299  1468666238477864962  RT @AzamBaloshi: PPP District South Held Prote...   \n\n    lang           location            posted_at  \n0     en     the simulation  2021-12-08 19:33:51  \n1     en               None  2021-12-08 19:33:55  \n2     en    London, England  2021-12-08 19:33:57  \n3     hi               None  2021-12-08 19:34:01  \n4     en               None  2021-12-08 19:34:03  \n..   ...                ...                  ...  \n295   en               None  2021-12-08 19:38:09  \n296   en               None  2021-12-08 19:38:09  \n297   en               None  2021-12-08 19:38:10  \n298   en               None  2021-12-08 19:38:11  \n299   en  Karachi, Pakistan  2021-12-08 19:38:12  \n\n[300 rows x 5 columns]"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "protest_df"}, {"cell_type": "code", "execution_count": 9, "id": "c07446bf", "metadata": {}, "outputs": [], "source": "violent_df = pd.DataFrame(protest_df[protest_df['lang']=='en']['text'], columns=['text']) # Violent word detection\nlocation_df = protest_df[['location', 'id']] # location of tweet\nwhere_df = protest_df # find location in context"}, {"cell_type": "code", "execution_count": 8, "id": "cf80bd82", "metadata": {}, "outputs": [], "source": "import numpy as np\nimport pandas as pd\nimport re"}, {"cell_type": "markdown", "id": "6d4db7a5", "metadata": {}, "source": "### Location of tweet"}, {"cell_type": "code", "execution_count": 10, "id": "db1cfb94", "metadata": {}, "outputs": [], "source": "def only_country(text):\n    text = text.lower()\n    text = text.replace(\",\", \" \")\n    spl_space_trigger = text.split(\" \")\n    \n    if len(spl_space_trigger) > 1:\n        text = spl_space_trigger[-1]\n    else:\n        return text\n    \n    if text == 'kingdom' or text == 'england':\n        text = 'uk'\n    elif text == 'states':\n        text = 'usa'\n    elif text == '':\n        text = 'undefined'\n        \n    return text"}, {"cell_type": "code", "execution_count": 11, "id": "fe3b3691", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/tmp/ipykernel_5234/1134729739.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  location_df['location'] = location_df.apply(lambda row : only_country(row['location']) if(np.all(pd.notnull(row['location']))) else row['location'], axis=1)\n"}], "source": "location_df['location'] = location_df.apply(lambda row : only_country(row['location']) if(np.all(pd.notnull(row['location']))) else row['location'], axis=1)"}, {"cell_type": "code", "execution_count": 12, "id": "479bc4fc", "metadata": {}, "outputs": [], "source": "location_of_tweet = location_df.groupby(\"location\").count().sort_values(by='id', ascending=False).head(10)"}, {"cell_type": "code", "execution_count": 13, "id": "a1dbbdf1", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n    <tr>\n      <th>location</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>uk</th>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>undefined</th>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>usa</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>london</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>nigeria</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>pakistan</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>ca</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>deutschland</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>canada</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>serbia</th>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "             id\nlocation       \nuk           33\nundefined    13\nusa          11\nlondon        8\nnigeria       6\npakistan      5\nca            4\ndeutschland   4\ncanada        4\nserbia        3"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "location_of_tweet"}, {"cell_type": "markdown", "id": "18d14068", "metadata": {}, "source": "## Location in context"}, {"cell_type": "code", "execution_count": 14, "id": "3dd443b5", "metadata": {}, "outputs": [], "source": "import spacy\nfrom spacy import displacy "}, {"cell_type": "code", "execution_count": 15, "id": "77a6b39d", "metadata": {}, "outputs": [{"data": {"text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Multiple tornado warnings were issued for parts of \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    New York\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n on \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Sunday\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    night\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n</mark>\n.The \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    first\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n</mark>\n warning, which expired at \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    9 p.m.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n</mark>\n, covered the \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Bronx\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n, \n<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Yonkers\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n</mark>\n and \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    New Rochelle\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n. \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    More than 2 million\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n</mark>\n people live in the impacted area.</div></span>", "text/plain": "<IPython.core.display.HTML object>"}, "metadata": {}, "output_type": "display_data"}], "source": "nlp = spacy.load(\"en_core_web_sm\")\n# Text with nlp\ndoc = nlp(\" Multiple tornado warnings were issued for parts of New York on Sunday night.The first warning, which expired at 9 p.m., covered the Bronx, Yonkers and New Rochelle. More than 2 million people live in the impacted area.\")\n# Display Entities\ndisplacy.render(doc, style=\"ent\")"}, {"cell_type": "code", "execution_count": 16, "id": "95c0f143", "metadata": {}, "outputs": [], "source": "def clean_line(text):\n    text = re.sub(r\"http\\S+\", \"\", text)\n    text = re.sub(r\"@[A-Za-z0-9]+\", \"\", text)\n    text = re.sub(r\"#[A-Za-z0-9]+\", \"\", text)\n    text = text.replace(\":\",\"\")\n    text = text.lower()\n    text = text.strip()\n    return text\n\ndef loc_from_text(df):\n    new_df = df.copy()\n    new_df = new_df[new_df['lang']=='en']\n    text_list = new_df['text']\n    loc = []\n    for text in text_list:\n        doc = nlp(text)\n        loc.extend(ent.text for ent in doc.ents if ent.label_ in ['GPE'])\n    return loc"}, {"cell_type": "code", "execution_count": 17, "id": "a47a8fee", "metadata": {}, "outputs": [], "source": "loc_context = loc_from_text(where_df)"}, {"cell_type": "code", "execution_count": 18, "id": "62fd3ac0", "metadata": {}, "outputs": [], "source": "loc_context_df = pd.DataFrame(data = loc_context, columns=['location'])"}, {"cell_type": "code", "execution_count": 19, "id": "e1514a57", "metadata": {}, "outputs": [], "source": "loc_context_df['location'] = loc_context_df.apply(lambda row : clean_line(row['location']), axis=1)\nloc_context_df = loc_context_df.drop(loc_context_df[loc_context_df['location'] == \"\"].index)"}, {"cell_type": "code", "execution_count": 20, "id": "a5f49ee2", "metadata": {}, "outputs": [], "source": "loc_result_df = pd.DataFrame(loc_context_df.value_counts().head(10), columns=['count'])"}, {"cell_type": "code", "execution_count": 21, "id": "a39955db", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>location</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>london</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>canada</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>australia</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>uk</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>china</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>america</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>austria</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>lyari</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>chile</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>\ud83c\udde7|</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "           count\nlocation        \nlondon         7\ncanada         6\naustralia      5\nuk             4\nchina          4\namerica        3\naustria        3\nlyari          3\nchile          3\n\ud83c\udde7|             2"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "loc_result_df"}, {"cell_type": "markdown", "id": "bda26abe", "metadata": {}, "source": "## Violent Detection"}, {"cell_type": "code", "execution_count": 22, "id": "72ee3bb1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<pyspark.sql.session.SparkSession object at 0x7f8480123a00>\n"}], "source": "import findspark\nfindspark.init()\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.functions import udf\n\n# Auxiliar functions\ndef equivalent_type(f):\n    if f == 'datetime64[ns]': return TimestampType()\n    elif f == 'int64': return LongType()\n    elif f == 'int32': return IntegerType()\n    elif f == 'float64': return FloatType()\n    else: return StringType()\n\ndef define_structure(string, format_type):\n    try: typo = equivalent_type(format_type)\n    except: typo = StringType()\n    return StructField(string, typo)\n\n# Given pandas dataframe, it will return a spark's dataframe.\ndef pandas_to_spark(pandas_df):\n    columns = list(pandas_df.columns)\n    types = list(pandas_df.dtypes)\n    struct_list = []\n    for column, typo in zip(columns, types): \n        struct_list.append(define_structure(column, typo))\n    p_schema = StructType(struct_list)\n    return sqlContext.createDataFrame(pandas_df, p_schema)\n\nspark = (SparkSession\n         .builder\n         .appName(\"DataFrameHandOn\")\n         .master(\"local[*]\")\n         .getOrCreate())\nprint(spark)"}, {"cell_type": "code", "execution_count": 23, "id": "e07fb31e", "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[text: string]"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "spark_df = pandas_to_spark(violent_df)\nspark_df.cache()"}, {"cell_type": "code", "execution_count": 24, "id": "1b6a07bb", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "\r[Stage 0:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|                text|\n+--------------------+\n|RT @NadiaWhittome...|\n|RT @MintPressNews...|\n|Woooiiiii folks i...|\n|Where and when do...|\n|RT @Ysbryd5: Nurs...|\n|RT @AndersonAfDMd...|\n|RT @AlinejadMasih...|\n|RT @TomPope695079...|\n|The Palestinian p...|\n|RT @GeorgeMonbiot...|\n+--------------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "\r                                                                                \r"}], "source": "spark_df.show(10)"}, {"cell_type": "code", "execution_count": 25, "id": "ed00ac0e", "metadata": {}, "outputs": [], "source": "def preprocess(text_string):\n    \"\"\"\n    Accepts a text string and replaces:\n    1) urls with URLHERE\n    2) lots of whitespace with one instance\n    3) mentions with MENTIONHERE\n\n    This allows us to get standardized counts of urls and mentions\n    Without caring about specific people mentioned\n    \"\"\"\n    space_pattern = '\\s+'\n    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    mention_regex = '@[\\w\\-]+'\n    parsed_text = re.sub(space_pattern, ' ', str(text_string))\n    parsed_text = re.sub(giant_url_regex, '', str(parsed_text))\n    parsed_text = re.sub(mention_regex, '', str(parsed_text))\n    parsed_text = re.sub(\"[^a-zA-Z:,]+\", ' ', str(parsed_text))\n    parsed_text = parsed_text.replace('RT', '')\n    parsed_text = parsed_text.replace('!', '')\n    parsed_text = parsed_text.replace(':', '')\n    parsed_text = parsed_text.strip('\\'\"')\n    parsed_text = parsed_text.lower()\n    parsed_text = parsed_text.lstrip()\n    \n    return parsed_text"}, {"cell_type": "code", "execution_count": 26, "id": "892def9e", "metadata": {}, "outputs": [], "source": "txt_process_udf = udf(preprocess, StringType())\nnew_df = spark_df.withColumn('text', txt_process_udf('text'))"}, {"cell_type": "code", "execution_count": 27, "id": "fa167a18", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|                text|\n+--------------------+\n|the downing stree...|\n|media bears a res...|\n|woooiiiii folks i...|\n|where and when do...|\n|nurse karen organ...|\n|australia, austri...|\n|this father who i...|\n|hundreds of thous...|\n|the palestinian p...|\n|this should be al...|\n+--------------------+\nonly showing top 10 rows\n\n"}], "source": "new_df.show(10)"}, {"cell_type": "markdown", "id": "ea36c14e", "metadata": {}, "source": "#### Prediction"}, {"cell_type": "code", "execution_count": 28, "id": "6bf1cde7", "metadata": {}, "outputs": [], "source": "import xgboost as xgb\nfrom pyspark.ml.feature import Tokenizer, Word2Vec\nfrom pyspark.ml import Pipeline"}, {"cell_type": "code", "execution_count": 29, "id": "33b0c173", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "21/12/08 19:44:16 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n21/12/08 19:44:16 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"}], "source": "# Load trained parameters from GCS\nw2v = Word2Vec.load(\"gs://twitter_testtt/w2v_model1\")\n\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nw2v_pipeline = Pipeline(stages=[tokenizer, w2v])\nw2v_pipeline_model = w2v_pipeline.fit(new_df)\ntrain_df = w2v_pipeline_model.transform(new_df)"}, {"cell_type": "code", "execution_count": 30, "id": "ffeb5daa", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+--------------------+\n|                text|               words|            Features|\n+--------------------+--------------------+--------------------+\n|the downing stree...|[the, downing, st...|[-0.0105149733019...|\n|media bears a res...|[media, bears, a,...|[-0.0083240476390...|\n|woooiiiii folks i...|[woooiiiii, folks...|[-0.0110597727221...|\n|where and when do...|[where, and, when...|[-0.0114352357632...|\n|nurse karen organ...|[nurse, karen, or...|[-0.0118300816852...|\n|australia, austri...|[australia,, aust...|[-0.0069386506220...|\n|this father who i...|[this, father, wh...|[-0.0137400973222...|\n|hundreds of thous...|[hundreds, of, th...|[-0.0158928056286...|\n|the palestinian p...|[the, palestinian...|[-0.0078335809833...|\n|this should be al...|[this, should, be...|[-0.0098890137349...|\n+--------------------+--------------------+--------------------+\nonly showing top 10 rows\n\n"}], "source": "train_df.show(10)"}, {"cell_type": "code", "execution_count": 31, "id": "8d991382", "metadata": {}, "outputs": [], "source": "# Load XGBoost model parameters\nmodel = xgb.Booster()\nmodel.load_model(\"./model1.bst\")"}, {"cell_type": "code", "execution_count": 32, "id": "e220314d", "metadata": {}, "outputs": [], "source": "train_features = train_df.select(\"Features\").collect()\nX_train = np.asarray([v[0].toArray() for v in train_features])\nX_train = xgb.DMatrix(X_train)\npred = model.predict(X_train)"}, {"cell_type": "code", "execution_count": 33, "id": "46190a6c", "metadata": {}, "outputs": [], "source": "pred_df = pd.DataFrame(pred.astype(int), columns=[\"class\"])\nviolent_result_df = pd.DataFrame(pred_df.value_counts(), columns=['count'])"}, {"cell_type": "code", "execution_count": 34, "id": "1311deba", "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>237</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "       count\nclass       \n1        237\n0         25"}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": "violent_result_df"}, {"cell_type": "markdown", "id": "c760dbf8", "metadata": {}, "source": "# Save result to BigQuery ---> BI"}, {"cell_type": "code", "execution_count": 35, "id": "3e2906f7", "metadata": {}, "outputs": [], "source": "from google.cloud import bigquery\n\nclient = bigquery.Client()\ntable_id1 = 'ns01-project.results.tweets_location'\ntable_id2 = 'ns01-project.results.context_location'\ntable_id3 = 'ns01-project.results.violent_count'"}, {"cell_type": "code", "execution_count": 240, "id": "99e4137a", "metadata": {}, "outputs": [], "source": "job_config_table1 = bigquery.LoadJobConfig(schema=[\n    bigquery.SchemaField(\"location\", \"STRING\"),\n    bigquery.SchemaField(\"id\", \"INT64\")\n])\n\njob1 = client.load_table_from_dataframe(\n    location_of_tweet, table_id1, job_config=job_config_table1\n)"}, {"cell_type": "code", "execution_count": 242, "id": "ae1b938d", "metadata": {}, "outputs": [], "source": "job_config_table2 = bigquery.LoadJobConfig(schema=[\n    bigquery.SchemaField(\"location\", \"STRING\"),\n    bigquery.SchemaField(\"count\", \"INT64\")\n])\n\njob2 = client.load_table_from_dataframe(\n    loc_result_df, table_id2, job_config=job_config_table2\n)"}, {"cell_type": "code", "execution_count": 243, "id": "660eec92", "metadata": {}, "outputs": [], "source": "job_config_table3 = bigquery.LoadJobConfig(schema=[\n    bigquery.SchemaField(\"class\", \"INT64\"),\n    bigquery.SchemaField(\"count\", \"INT64\")\n])\n\njob3 = client.load_table_from_dataframe(\n    violent_result_df, table_id3, job_config=job_config_table3\n)"}, {"cell_type": "code", "execution_count": null, "id": "d80a4776", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "4cae3711", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "c8ad6dc9", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "f5cb2866", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "2146ae7f", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 5}